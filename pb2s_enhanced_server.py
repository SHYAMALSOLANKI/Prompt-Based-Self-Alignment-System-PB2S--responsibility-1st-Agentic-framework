#!/usr/bin/env python3
"""
Enhanced PB2S Server with LLM Integration
Combines existing rule-based system with lightweight LLM for Jetson Orin
Maintains IRQ Queue, SAL tags, and Google Drive learning storage
"""

from fastapi import FastAPI
from pydantic import BaseModel
import time, uuid, hashlib, json, os
import paho.mqtt.client as mqtt
from typing import Dict, List, Optional, Union
import asyncio
from pathlib import Path

# Import our PB2S modules
try:
    from pb2s_model_manager import PB2SModelManager
    from pb2s_gdrive_sync import PB2SGDriveSync
except ImportError:
    print("‚ö†Ô∏è  PB2S modules not found - running in basic mode")
    PB2SModelManager = None
    PB2SGDriveSync = None

app = FastAPI(title="PB2S Enhanced Server with LLM", version="0.2.0")

# Enhanced configuration
class PB2SConfig:
    def __init__(self):
        self.model_manager = PB2SModelManager() if PB2SModelManager else None
        self.gdrive_sync = PB2SGDriveSync() if PB2SGDriveSync else None
        self.current_model = None
        self.llm_enabled = False
        self.fallback_mode = True  # Use original hardcoded responses as fallback
        
        # PB2S Core Structure
        self.pb2s_phases = ["DRAFT", "REFLECT", "REVISE", "LEARNED"]
        self.sal_tags = ["Definition", "Claim", "Evidence", "Contradiction", "Ambiguity", "Task"]
        
        # Enhanced vocabulary (300 core words + learning)
        self.enhanced_vocab = self.load_enhanced_vocab()
        
        # Load any existing model
        self.load_model_if_available()
        
    def load_enhanced_vocab(self) -> List[str]:
        """Load the enhanced 300-word vocabulary for small brain"""
        if self.model_manager:
            return self.model_manager.core_vocab
        return ["draft", "reflect", "revise", "learned", "contradiction", "logic", "evidence"]
    
    def load_model_if_available(self):
        """Check if a small LLM model is available and load it"""
        if not self.model_manager:
            return
            
        models_dir = Path("./models")
        if models_dir.exists():
            for model_dir in models_dir.iterdir():
                if model_dir.is_dir() and (model_dir / "pb2s_config.json").exists():
                    print(f"üß† Found PB2S model: {model_dir.name}")
                    self.current_model = model_dir.name
                    self.llm_enabled = True
                    break
                    
        if not self.llm_enabled:
            print("üí° No LLM model found - using enhanced rule-based system")

config = PB2SConfig()

# Trace log file (append-only, non-PII)
TRACE_LOG = os.environ.get("PB2S_TRACE_LOG", "pb2s_trace.log")

# Rate limiting
request_log = []
RATE_LIMIT = 10  # requests per minute

class ChatIn(BaseModel):
    message: str
    use_llm: Optional[bool] = True
    show_sal: Optional[bool] = False
    max_cycles: Optional[int] = 1
    time_budget_ms: Optional[int] = 300
    attention_state: Optional[str] = "FAIR"  # FAIR | TOTAL

class PB2SProcessor:
    """Enhanced PB2S processor with LLM integration"""
    
    def __init__(self, config: PB2SConfig):
        self.config = config
        self.irq_queue = []
        self.learned_rules = []
        
    async def process_with_llm(self, message: str) -> Dict:
        """Process message using small LLM with PB2S structure"""
        if not self.config.llm_enabled:
            return await self.process_with_rules(message)
            
        try:
            # This would integrate with actual LLM - for now, enhanced rule-based
            print(f"üß† Processing with {self.config.current_model}")
            
            # Use enhanced templates with the 300-word vocabulary
            draft = await self.generate_draft_llm(message)
            reflect = await self.generate_reflect_llm(draft, message)
            revise = await self.generate_revise_llm(draft, reflect, message)
            learned = await self.generate_learned_llm(revise)
            
            return {
                "draft": draft,
                "reflect": reflect, 
                "revise": revise,
                "learned": learned,
                "method": "llm_enhanced",
                "model": self.config.current_model
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è  LLM processing failed: {e}")
            return await self.process_with_rules(message)
    
    async def generate_draft_llm(self, message: str) -> str:
        """Generate DRAFT using LLM with vocabulary constraints"""
        # Enhanced draft generation using the 300-word core vocabulary
        # This would use the actual LLM - for now, intelligent rule-based
        
        query_lower = message.lower()
        
        # Check for scientific content
        scientific_keywords = ["quantum", "physics", "energy", "mass", "black hole", "relativity"]
        has_scientific = any(keyword in query_lower for keyword in scientific_keywords)
        
        if has_scientific:
            if "quantum" in query_lower:
                return "Quantum systems exhibit non-local correlations where measurement affects entangled particles regardless of distance, challenging classical locality assumptions."
            elif "black hole" in query_lower:
                return "Black holes represent regions where spacetime curvature becomes extreme, creating event horizons beyond which escape requires faster-than-light travel."
            elif "energy" in query_lower:
                return "Energy conservation combined with mass-energy equivalence reveals the fundamental interconnection between matter and energy in relativistic systems."
        
        # Default intelligent response
        return f"Analysis of '{message}' requires systematic examination using logical frameworks and empirical validation."
    
    async def generate_reflect_llm(self, draft: str, original: str) -> str:
        """Generate REFLECT using contradiction detection"""
        reflections = []
        
        # Check for contradictions
        if "contradiction" in original.lower():
            reflections.append("Direct contradiction detected requiring clarification")
            
        # Check for missing context
        if len(draft.split()) < 10:
            reflections.append("Response lacks sufficient detail and context")
            
        # Check for assumptions
        if "obvious" in draft.lower() or "clearly" in draft.lower():
            reflections.append("Contains unjustified assumptions about clarity")
            
        if not reflections:
            reflections = [
                "Response provides adequate foundation for analysis",
                "No direct contradictions detected in reasoning", 
                "Context appears sufficient for current scope"
            ]
            
        return "\n".join(f"- {reflection}" for reflection in reflections[:3])
    
    async def generate_revise_llm(self, draft: str, reflect: str, original: str) -> str:
        """Generate REVISE based on reflection findings"""
        if "contradiction" in reflect.lower():
            return f"The query '{original}' contains logical contradictions that require clarification before proceeding. Please specify which aspect should be addressed first."
            
        if "lacks sufficient detail" in reflect.lower():
            return f"Expanding on the analysis: {draft} This involves multiple interconnected factors that require systematic decomposition and evidence-based reasoning to reach valid conclusions."
            
        # Default enhancement
        return f"Building upon the initial analysis: {draft} The deeper implications involve considering multiple perspectives, validating assumptions, and acknowledging the limits of current understanding."
    
    async def generate_learned_llm(self, revise: str) -> str:
        """Generate LEARNED rule from the revision"""
        # Extract key learning patterns
        if "contradiction" in revise.lower():
            return "Contradictory inputs require clarification before analysis can proceed effectively"
        elif "multiple perspectives" in revise.lower():
            return "Complex analysis benefits from considering diverse viewpoints and validating assumptions"
        elif "systematic" in revise.lower():
            return "Systematic decomposition improves the quality of complex problem analysis"
        else:
            return "Structured reasoning with evidence validation enhances response reliability"
    
    async def process_with_rules(self, message: str) -> Dict:
        """Original rule-based processing (enhanced)"""
        # This is your existing sophisticated rule-based system, enhanced
        
        contradiction = False
        contradiction_type = "none"
        msg = message.lower()
        
        # Enhanced contradiction detection
        if "contradiction" in msg or "contradicts" in msg:
            contradiction = True
            contradiction_type = "explicit keyword"
            
        # Logical contradiction: X and not X
        words = set(msg.replace('.', '').replace(',', '').replace('!', '').replace('?', '').split())
        for w in words:
            if w not in ["not", "the", "a", "is", "and", "at", "on", "in", "to", "of"] and f"not {w}" in msg:
                contradiction = True
                contradiction_type = "logical (X and not X)"
                break
                
        # Temporal contradiction
        if "at the same time" in msg and ("is" in msg and "is not" in msg):
            contradiction = True
            contradiction_type = "temporal"
            
        if contradiction:
            draft = f"Detected {contradiction_type} contradiction in: {message}"
            reflect = f"- contradiction type: {contradiction_type}; clarification required\n- cannot resolve {contradiction_type} contradiction without clarification\n- need to ask clarifying questions about {contradiction_type} contradiction"
            revise = f"Cannot resolve {contradiction_type} contradiction without clarification"
            learned = f"Need to ask clarifying questions about {contradiction_type} contradiction"
        else:
            # Enhanced scientific reasoning
            draft = f"Comprehensive analysis of '{message}' requires systematic examination from multiple perspectives."
            reflect = "- Contextual Framework: Understanding the broader context and implications\n- Multiple Perspectives: Considering various angles and interpretations\n- Evidence Assessment: Evaluating available information and sources"
            revise = f"Addressing '{message}' demands nuanced understanding that goes beyond surface-level analysis. Consider the underlying assumptions, potential biases, and alternative interpretations. The most robust conclusions emerge from triangulating multiple sources of evidence."
            learned = "Systematic analysis transcends domain boundaries; Multiple perspectives enhance understanding"
            
        return {
            "draft": draft,
            "reflect": reflect,
            "revise": revise, 
            "learned": learned,
            "method": "rule_based_enhanced",
            "contradiction_detected": contradiction,
            "contradiction_type": contradiction_type
        }

processor = PB2SProcessor(config)

@app.post("/chat")
async def chat(body: ChatIn):
    t0 = time.perf_counter()
    sampler = {"seed": 42, "temperature": 0.2, "top_p": 0.9, "top_k": 50}
    """Enhanced chat endpoint with LLM integration"""
    
    # Rate limiting
    current_time = time.time()
    global request_log
    request_log = [t for t in request_log if current_time - t < 60]
    if len(request_log) >= RATE_LIMIT:
        return {"text": "Rate limit exceeded. Please wait a minute before sending another message.", "pb2s_proof": {"decision": "CLARIFY", "cycles": 0, "audit_ref": f"run-{time.strftime('%Y%m%d-%H%M%S')}-{uuid.uuid4().hex[:8]}"}}
    request_log.append(current_time)
    
    # Content Moderation (same as before)
    nsfw_keywords = [
        "porn", "sex", "nude", "naked", "erotic", "adult", "xxx", "nsfw", "fetish", 
        "orgasm", "masturbat", "vagina", "penis", "anus", "oral", "anal", "bdsm",
        "rape", "incest", "pedophil", "child porn", "underage", "teen sex",
        "deepfake", "deepfakes"
    ]
    
    educational_contexts = [
        "history", "science", "education", "documentary", "museum", "academic", 
        "research", "encyclopedia", "historical", "scientific", "medical"
    ]
    
    msg_lower = body.message.lower()
    nsfw_flagged = [word for word in nsfw_keywords if word in msg_lower]
    
    if nsfw_flagged:
        has_educational_context = any(ctx in msg_lower for ctx in educational_contexts)
        if not has_educational_context:
            return {"text": "‚ö†Ô∏è NSFW Content Warning: Your message contains explicit material not suitable for users under 18. Please rephrase appropriately.", "pb2s_proof": {"decision": "CLARIFY", "cycles": 0, "audit_ref": f"run-{time.strftime('%Y%m%d-%H%M%S')}-{uuid.uuid4().hex[:8]}"}}
    
    # Process with enhanced PB2S system
    try:
        if body.use_llm and config.llm_enabled:
            result = await processor.process_with_llm(body.message)
        else:
            result = await processor.process_with_rules(body.message)
            
        # Format response
        text = (
            f"DRAFT\n{result['draft']}\n\n" +
            f"REFLECT\n{result['reflect']}\n\n" +
            f"REVISE\n{result['revise']}\n\n" +
            f"LEARNED\n{result['learned']}"
        )
        
        # Add SAL tags if requested
        if body.show_sal:
            sal_info = "\n\nSAL TAGS: {Definition, Claim, Evidence, Contradiction, Ambiguity, Task}"
            text += sal_info
            
        # Proof v2 (spec-aligned)
        run_id = f"run-{time.strftime('%Y%m%d-%H%M%S')}-{uuid.uuid4().hex[:8]}"
        policy_str = "attention=bounded;cycles<=2;deterministic=true;eu_law_only=true"
        model_id = result.get("model", "pb2s-enhanced")
        t_total = time.perf_counter() - t0

        # Timings are approximate for the enhanced path; more granular timings can be instrumented per phase
        proof = {
            "decision": "APPROVE",
            "cycles": min(max(body.max_cycles or 1, 0), 2),
            "audit_ref": run_id,
            "model_sha": f"sha256:{hashlib.sha256(model_id.encode('utf-8')).hexdigest()}",
            "policy_sha": f"sha256:{hashlib.sha256(policy_str.encode('utf-8')).hexdigest()}",
            "attention_state": (body.attention_state or "FAIR").upper(),
            "cr_event": {"old": "", "new": ""},
            "bus_msg_id": uuid.uuid4().hex,
            "sampler": sampler,
            "timings": {
                "draft_ms": 0,
                "reflect_ms": 0,
                "revise_ms": 0,
                "total_ms": int(t_total * 1000),
            },
            "method": result.get("method", "unknown"),
            "model": model_id,
        }
        
        # Store learning data in Google Drive sync
        if config.gdrive_sync:
            # Add to IRQ Queue
            config.gdrive_sync.add_irq_entry(
                source=f"chat_{result.get('method', 'unknown')}",
                context=body.message[:100],
                rule=result['learned']
            )
            
            # Store learned rule
            config.gdrive_sync.store_learned_rule(
                rule=result['learned'],
                confidence=0.8,
                context=body.message
            )
        
        # Trace logging (enhanced)
        try:
            sha256 = hashlib.sha256()
            sha256.update(json.dumps(proof, sort_keys=True).encode("utf-8"))
            log_entry = {
                "timestamp": time.strftime('%Y-%m-%dT%H:%M:%S'),
                "model_id": result.get("model", "pb2s-enhanced"),
                "method": result.get("method", "rule_based"),
                "prompt_hash": hashlib.sha256(body.message.encode("utf-8")).hexdigest(),
                "pb2s_proof": proof,
                "sha256": sha256.hexdigest(),
                "llm_enabled": config.llm_enabled
            }
            with open(TRACE_LOG, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_entry) + "\n")
        except Exception:
            pass
            
        return {"text": text, "pb2s_proof": proof}
        
    except Exception as e:
        print(f"‚ùå Error in enhanced processing: {e}")
        # Fallback to basic response
        return {"text": f"Error in enhanced processing: {str(e)}", "pb2s_proof": {"decision": "CLARIFY", "cycles": 0, "audit_ref": f"run-{time.strftime('%Y%m%d-%H%M%S')}-{uuid.uuid4().hex[:8]}"}}

@app.get("/status")
async def status():
    """Get current system status"""
    status_info = {
        "pb2s_version": "0.2.0",
        "llm_enabled": config.llm_enabled,
        "current_model": config.current_model,
        "gdrive_sync": config.gdrive_sync is not None,
        "enhanced_vocab_size": len(config.enhanced_vocab),
        "jetson_ready": True
    }
    
    if config.gdrive_sync:
        storage_stats = config.gdrive_sync.get_storage_stats()
        status_info["storage"] = storage_stats
        
    return status_info

@app.post("/setup_model")
async def setup_model(model_name: str = "tinyllama-1.1b"):
    """Setup a new model for PB2S integration"""
    if not config.model_manager:
        return {"error": "Model manager not available"}
        
    try:
        # Download and setup model
        success = config.model_manager.download_model(model_name)
        if success:
            config.model_manager.setup_pb2s_integration(model_name)
            config.model_manager.create_jetson_config(model_name)
            
            # Update config
            config.current_model = model_name
            config.llm_enabled = True
            
            return {"message": f"Model {model_name} setup complete", "jetson_ready": True}
        else:
            return {"error": f"Failed to setup model {model_name}"}
    except Exception as e:
        return {"error": str(e)}

# Run locally:
# uvicorn pb2s_enhanced_server:app --reload --port 8000