#!/usr/bin/env python3
"""
KoboldAI CPP Integration Setup Guide for PB2S Dashboard
Complete instructions for setting up local LLM with PB2S structure
"""

import os
import subprocess
import platform

def print_setup_guide():
    """Print comprehensive setup guide for KoboldAI CPP integration"""
    
    print("ü§ñ KoboldAI CPP + PB2S Dashboard Integration Guide")
    print("=" * 60)
    print()
    
    print("üìã What You Have Now:")
    print("‚úÖ KoboldAI CPP connector with PB2S structure integration")
    print("‚úÖ Enhanced dashboard with local model support")
    print("‚úÖ Automatic PB2S format (DRAFT‚ÜíREFLECT‚ÜíREVISE‚ÜíLEARNED)")
    print("‚úÖ Fallback system if KoboldAI is offline")
    print("‚úÖ Your existing Main Brain system intact")
    print()
    
    print("üéØ Setup Steps:")
    print()
    
    print("1Ô∏è‚É£ DOWNLOAD KoboldAI CPP 1.98.1")
    print("   ‚Ä¢ Windows: https://github.com/LostRuins/koboldcpp/releases")
    print("   ‚Ä¢ Download: koboldcpp.exe (or build from source)")
    print("   ‚Ä¢ Place in easy-to-access folder")
    print()
    
    print("2Ô∏è‚É£ GET A COMPATIBLE MODEL")
    print("   üì• Recommended small models for testing:")
    print("   ‚Ä¢ TinyLlama-1.1B-Chat (2GB): https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF")
    print("   ‚Ä¢ Phi-2 (5GB): https://huggingface.co/microsoft/phi-2-GGUF")
    print("   ‚Ä¢ OpenHermes 2.5 (7GB): https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF")
    print()
    print("   üí° Download the .gguf file (GGUF format required)")
    print("   üí° Q4_K_M or Q5_K_M quantization recommended for balance")
    print()
    
    print("3Ô∏è‚É£ START KoboldAI CPP SERVER")
    print("   Open terminal/command prompt and run:")
    print("   ```")
    if platform.system() == "Windows":
        print("   koboldcpp.exe --port 5001 --host 0.0.0.0 your_model.gguf")
    else:
        print("   ./koboldcpp --port 5001 --host 0.0.0.0 your_model.gguf")
    print("   ```")
    print()
    print("   üîß Optional parameters:")
    print("   ‚Ä¢ --threads 8           (use 8 CPU threads)")
    print("   ‚Ä¢ --blasthreads 4       (BLAS acceleration)")
    print("   ‚Ä¢ --gpulayers 20        (offload 20 layers to GPU)")
    print("   ‚Ä¢ --contextsize 2048    (context window size)")
    print()
    
    print("4Ô∏è‚É£ VERIFY KoboldAI IS RUNNING")
    print("   ‚Ä¢ Open browser: http://localhost:5001")
    print("   ‚Ä¢ You should see KoboldAI web interface")
    print("   ‚Ä¢ Model should be loaded and ready")
    print()
    
    print("5Ô∏è‚É£ START YOUR PB2S DASHBOARD")
    print("   ```")
    print("   streamlit run pb2s_dashboard.py --server.port 8502")
    print("   ```")
    print()
    
    print("6Ô∏è‚É£ TEST THE INTEGRATION")
    print("   ‚Ä¢ Open dashboard: http://localhost:8502")
    print("   ‚Ä¢ You'll see TWO nodes now:")
    print("     - Main Brain (your existing server)")
    print("     - Local Model (KoboldAI)")
    print("   ‚Ä¢ Both should show online status")
    print("   ‚Ä¢ Type a question and send to Local Model")
    print("   ‚Ä¢ Get PB2S structured response!")
    print()
    
    print("üé® DASHBOARD FEATURES:")
    print("‚úÖ Dual AI nodes (Main Brain + Local Model)")
    print("‚úÖ Real-time status checking")
    print("‚úÖ PB2S structure enforcement")
    print("‚úÖ Raw response viewing")
    print("‚úÖ Model information display")
    print("‚úÖ Automatic fallback handling")
    print()
    
    print("üîç EXAMPLE INTERACTION:")
    print("You ask: 'What is quantum computing?'")
    print()
    print("Local Model responds:")
    print("""DRAFT
Quantum computing uses quantum mechanical phenomena like superposition and entanglement to process information.

REFLECT
- Should include specific quantum advantages
- Missing mention of qubit vs classical bit differences  
- Need to address current limitations

REVISE
Quantum computing leverages quantum mechanical properties like superposition (qubits existing in multiple states) and entanglement (correlated qubit pairs) to perform certain calculations exponentially faster than classical computers. Current applications include cryptography, optimization, and scientific simulation, though practical quantum advantage remains limited to specific problems.

LEARNED
Quantum explanations require balancing technical accuracy with accessibility while noting current practical limitations""")
    print()
    
    print("‚öôÔ∏è CONFIGURATION OPTIONS:")
    print()
    print("üîß In kobold_connector.py you can adjust:")
    print("‚Ä¢ kobold_url = 'http://localhost:5001'  # Change port if needed")
    print("‚Ä¢ max_length = 512                      # Response length")
    print("‚Ä¢ temperature = 0.7                     # Creativity level")
    print("‚Ä¢ top_p = 0.9                          # Token selection")
    print()
    
    print("üìä TROUBLESHOOTING:")
    print()
    print("‚ùå 'Local Model offline'")
    print("   ‚Üí Check KoboldAI is running on port 5001")
    print("   ‚Üí Verify model is loaded (check browser interface)")
    print()
    print("‚ùå 'Generation failed'")
    print("   ‚Üí Model might be too small for complex PB2S structure")
    print("   ‚Üí Try simpler questions first")
    print("   ‚Üí Check KoboldAI logs for errors")
    print()
    print("‚ùå 'Malformed PB2S response'")
    print("   ‚Üí Some models need fine-tuning for structure")
    print("   ‚Üí Fallback response will be used")
    print("   ‚Üí Consider larger model or adjust prompt template")
    print()
    
    print("üöÄ ADVANCED USAGE:")
    print()
    print("üîó Multiple Models:")
    print("   ‚Ä¢ Run multiple KoboldAI instances on different ports")
    print("   ‚Ä¢ Add more nodes to dashboard configuration")
    print("   ‚Ä¢ Compare responses from different models")
    print()
    print("üß† Model Switching:")
    print("   ‚Ä¢ Stop KoboldAI (Ctrl+C)")
    print("   ‚Ä¢ Load different model")
    print("   ‚Ä¢ Restart - dashboard will auto-detect")
    print()
    print("‚ö° Performance Tuning:")
    print("   ‚Ä¢ Use GPU acceleration if available")
    print("   ‚Ä¢ Adjust thread count for your CPU")
    print("   ‚Ä¢ Monitor RAM usage with larger models")
    print()
    
    print("üéâ SUCCESS INDICATORS:")
    print("‚úÖ Dashboard shows 'Local Model (KoboldAI) is online'")
    print("‚úÖ Responses follow PB2S structure")
    print("‚úÖ Model info shows in expandable section")
    print("‚úÖ No connection errors in dashboard")
    print()
    
    print("üí° NEXT STEPS:")
    print("‚Ä¢ Try different models and compare results")
    print("‚Ä¢ Experiment with KoboldAI generation settings")
    print("‚Ä¢ Use both Main Brain and Local Model for comparison")
    print("‚Ä¢ Fine-tune the PB2S prompt template for better structure")
    print("‚Ä¢ Set up model switching for different tasks")
    print()
    
    print("üìö FILES CREATED:")
    print("‚Ä¢ kobold_connector.py     - KoboldAI integration")
    print("‚Ä¢ pb2s_dashboard.py       - Enhanced dashboard")
    print("‚Ä¢ setup_kobold_guide.py   - This guide")
    print()
    
    print("üîß Quick Test Command:")
    print("python kobold_connector.py  # Test connection")
    print()

def test_current_status():
    """Test current system status"""
    print("üîç CURRENT SYSTEM STATUS")
    print("=" * 30)
    
    # Test KoboldAI connection
    try:
        from kobold_connector import KoboldAICPPConnector
        kobold = KoboldAICPPConnector()
        status = kobold.check_connection()
        
        if status["status"] == "online":
            print("‚úÖ KoboldAI CPP: ONLINE")
            print(f"   Model: {status.get('model', 'Unknown')}")
            print(f"   URL: {status.get('url', 'Unknown')}")
        else:
            print("‚ùå KoboldAI CPP: OFFLINE")
            print(f"   Status: {status['status']}")
            print(f"   Message: {status.get('message', 'Unknown')}")
            
    except ImportError:
        print("‚ùå KoboldAI Connector: NOT FOUND")
        
    # Test Main Brain
    try:
        import requests
        resp = requests.get("http://127.0.0.1:8000/chat", timeout=2)
        print("‚úÖ Main Brain: ONLINE")
    except:
        print("‚ùå Main Brain: OFFLINE")
        
    print()
    
    # Check if dashboard files exist
    files_to_check = [
        "pb2s_dashboard.py",
        "kobold_connector.py", 
        "server/main.py"
    ]
    
    print("üìÅ FILE STATUS:")
    for file in files_to_check:
        if os.path.exists(file):
            print(f"‚úÖ {file}")
        else:
            print(f"‚ùå {file}")
    print()

if __name__ == "__main__":
    print_setup_guide()
    print()
    test_current_status()
    
    print("üöÄ Ready to start? Run these commands:")
    print("1. Start KoboldAI: koboldcpp.exe --port 5001 your_model.gguf")
    print("2. Start dashboard: streamlit run pb2s_dashboard.py --server.port 8502")
    print("3. Visit: http://localhost:8502")
    print()
    print("Need help? Run: python kobold_connector.py")